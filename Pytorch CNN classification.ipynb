{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da039ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "전체적인 구조\n",
    "\n",
    "#첫 번째 레이어\n",
    "합성곱(in_channel = 1, out_channel = 32, kernel_size = 3, stride = 1, padding = 1) + 활성화 함수(Activation function) ReLU\n",
    "맥스풀링(kernel_size = 2, stride = 2)\n",
    "\n",
    "#두 번째 레이어\n",
    "합성곱(in_channel = 32, out_channel = 64, kernel_size = 3, stride = 1, padding = 1) + 활성화 함수(Activation function) ReLU\n",
    "맥스풀링(kernel_size = 2, stride = 2)\n",
    "\n",
    "#세 번째 레이어\n",
    "batch_size x 7 x 7 x 64 => batch size = 3136 (특성맵을 펼치는 레이어)\n",
    "Fully connected(전결합층 뉴런 10개) + 활성화 함수 softmax\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67a93e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#구현에 필요한 라이브러리 불러오기\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "\n",
    "# as를 선언하지 않았을 경우 torch.nn.Conv2d() \n",
    "# as를 선언했을 경우 nn.Conv2d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a972fa7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텐서의 크기: torch.Size([1, 1, 28, 28]) \n"
     ]
    }
   ],
   "source": [
    "#임의의 텐서 생성 (1,1,28,28) -> MNIST데이터를 받기 위한 공간\n",
    "\n",
    "inputs = torch.Tensor(1,1,28,28) \n",
    "print (\"텐서의 크기: {} \".format(inputs.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc9ab4e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "#첫 번째 합성곱층 선언하기\n",
    "conv1 = nn.Conv2d(1, 32, kernel_size= 3, padding = 1) #Conv2d내의 인자값 (input_channel,output_channel, 커널 사이즈, 패딩)\n",
    "print(conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b29aa60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "#두 번째 합성곱층 선언하기\n",
    "conv2 = nn.Conv2d(32, 64, 3, padding = 1)\n",
    "print(conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4554760e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n"
     ]
    }
   ],
   "source": [
    "#세 번째 합성곱층 선언하기(풀링 레이어) \n",
    "pool = nn.MaxPool2d(2) #간단히 선언하면 선언 된 하나의 정수값을 통해 kernal size, stride가 결정되게 된다.\n",
    "print(pool)\n",
    "\n",
    "#pool = nn.MaxPool2d(kernel_size =2, stride=2, padding=0, dilation=1, ceil_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "740faedc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "#선언 된 레이어을 연결하는 과정\n",
    "#첫번째 레이어 지나가기\n",
    "out = conv1(inputs)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f132217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "#컨벌루셔널 레이어를 거쳐 갈 경우 마지막에 pooling layer가 존재함.\n",
    "out = pool(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3335ab09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "#두 번째 레이어 지나가기\n",
    "out = conv2(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d588123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "out = pool(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b9c89e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3136])\n"
     ]
    }
   ],
   "source": [
    "#view()함수를 사용해서 텐서를 펼치는 작업 (텐서를 통합한다)\n",
    "out = out.view(out.size(0), -1)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb7263dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "fc = nn.Linear(3136, 10) #fully connected: 전체를 연결(기초적인 신경망) \n",
    "                        #통합된 3136크기의 텐서를 통해 0~9까지의 결과를 갖게 되기 때문에 10개의 output\n",
    "out = fc(out)\n",
    "print(out.shape)\n",
    "\n",
    "#위까지가 전체 모델 설정 과정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4bdbd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#위에서 선언한 신경망을 통해서 MNIST(숫자 데이터셋) 분류 문제 해결하기\n",
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "875b4bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#torch.cuda.is_avilable()함수는 False/True의 boolean형태로 나타나게 되는데, CUDA를 사용 가능할 경우 True를 반환하기 때문에 \n",
    "#if 조건을 만족하는 device = 'cuda'가 되고, 사용이 불가능할 경우 False를 반환하기 때문에 else 조건을 만족하는 device = 'cpu'가 됨.\n",
    "\n",
    "#GPU 사용시에 고정시킬 시드를 선언\n",
    "torch.manual_seed(777)\n",
    "\n",
    "#만약 CPU가 아닌 GPU를 사용해서 훈련을 진행할 경우 고정 된 시드를 통해 GPU로 학습.\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "419654bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습에 사용되는 변수(파라미터들: 학습률, 에폭, 배치사이즈 등) 선언\n",
    "learning_rate = 0.001\n",
    "training_epoch = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "197254ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31.0%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102.8%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30.6%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#MNIST train, test 데이터셋을 torchvision.datasets를 통해 비교적으로 쉽게 가져오기\n",
    "\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                         train =True,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                        train=False,\n",
    "                        transform=transforms.ToTensor(),\n",
    "                        download=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7a2538d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터로더를 이용하여 배치크기를 지정\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f0cc1f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module): #CNN구조를 사용한 모델을 선언하기 위한 클래스\n",
    "    def __init__(self): #초기화 함수, 동시에 모델의 구조를 선언하는 함수\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.layer1 = torch.nn.Sequential(torch.nn.Conv2d(1,32, kernel_size=3, stride=1, padding=1),\n",
    "                                          torch.nn.ReLU(),\n",
    "                                          torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.layer2 = torch.nn.Sequential(torch.nn.Conv2d(32,64,kernel_size=3, stride=1, padding=1),\n",
    "                                         torch.nn.ReLU(),\n",
    "                                         torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.fc = torch.nn.Linear(7 * 7 * 64, 10, bias=True)\n",
    "        \n",
    "        torch.nn.init.xavier_uniform_(self.fc.weight)\n",
    "        \n",
    "    def forward(self,x): #레이어를 거치며 계산되는 가중치를 전달하기 위해 사용하는 함수\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0),-1)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3e9b34b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)\n",
    "# model이라는 객체를 통해서 CNN 클래스가 선언이 되고, 이는 .to(device)를 통해 gpu에서 연산을 하게 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7b215dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#비용함수(cost function = loss function)은 크로스엔트로피로 설정\n",
    "#옵티마이저는 Adam으로 설정\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d2522618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 배치의 수 : 600\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(data_loader)\n",
    "print('총 배치의 수 : {}'.format(total_batch))\n",
    "\n",
    "#MNIST dataset은 60,000개의 데이터를 가지고 있는데, batch_size를 100번으로 설정했으므로 총 600의 total_batch를 가지게 됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7eb5c8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    1] cost = 0.0243159197\n",
      "[Epoch:    2] cost = 0.0197941028\n",
      "[Epoch:    3] cost = 0.017394891\n",
      "[Epoch:    4] cost = 0.0132922707\n",
      "[Epoch:    5] cost = 0.0123913921\n",
      "[Epoch:    6] cost = 0.00983346254\n",
      "[Epoch:    7] cost = 0.00929936767\n",
      "[Epoch:    8] cost = 0.00705655525\n",
      "[Epoch:    9] cost = 0.00707010645\n",
      "[Epoch:   10] cost = 0.0069585382\n",
      "[Epoch:   11] cost = 0.00453357678\n",
      "[Epoch:   12] cost = 0.00409070123\n",
      "[Epoch:   13] cost = 0.00341323158\n",
      "[Epoch:   14] cost = 0.0036802548\n",
      "[Epoch:   15] cost = 0.00487362454\n"
     ]
    }
   ],
   "source": [
    "#epoch의 수에 따라 반복문을 반복하며 training 실행\n",
    "\n",
    "for epoch in range(training_epoch):\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for X, Y in data_loader:\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += cost / total_batch\n",
    "        \n",
    "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch +1, avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b494aa8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 958.00 MiB (GPU 0; 4.00 GiB total capacity; 1019.15 MiB already allocated; 528.50 MiB free; 1020.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_9620/972086753.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mY_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mcorrect_prediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorrect_prediction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ADMINI~1\\AppData\\Local\\Temp/ipykernel_9620/3400384043.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#레이어를 거치며 계산되는 가중치를 전달하기 위해 사용하는 함수\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    440\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 442\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    443\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 958.00 MiB (GPU 0; 4.00 GiB total capacity; 1019.15 MiB already allocated; 528.50 MiB free; 1020.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(len(mnist_test),1,28,28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "    \n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
